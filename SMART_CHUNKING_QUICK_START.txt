â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
SMART CHUNKING QUICK START (20-30s, NO MID-WORD CUTS)
Perfect for Speech Training & VAD Alignment
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

WHAT YOU'LL GET
---------------
âœ… Chunks between 20-30 seconds (random duration)
âœ… NO mid-word cuts (respects sentence boundaries)
âœ… Natural speech breaks
âœ… Perfect for audio processing and ML training

Example:
âŒ BAD:  "...à¦•à¦¥à¦¾ à¦¬à¦²" | "à¦¬ à¦†à¦œà¦•à§‡..."  (word cut in half)
âœ… GOOD: "...à¦•à¦¥à¦¾ à¦¬à¦²à¦¬" | "à¦†à¦œà¦•à§‡ à¦†à¦®à¦°à¦¾..." (clean break)


â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
3-STEP QUICK START
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â”Œâ”€ STEP 1: PREPARE BATCHES (2 minutes) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                    â”‚
â”‚  python prepare_bangla_batches.py                                 â”‚
â”‚                                                                    â”‚
â”‚  Creates 6 batches from your 275 Bangla videos                   â”‚
â”‚                                                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€ STEP 2: DOWNLOAD IN PARALLEL (1-2 hours) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                    â”‚
â”‚  Use smart_chunk_downloader.py on each platform:                 â”‚
â”‚                                                                    â”‚
â”‚  ğŸ”· Kaggle 1     â†’ bangla_batch_0.csv (50 videos)                â”‚
â”‚  ğŸ”¶ Colab 1      â†’ bangla_batch_1.csv (50 videos)                â”‚
â”‚  ğŸ”· GitHub       â†’ bangla_batch_2.csv (50 videos)                â”‚
â”‚  ğŸ”¶ Colab 2      â†’ bangla_batch_3.csv (50 videos)                â”‚
â”‚  ğŸ”· Kaggle 2     â†’ bangla_batch_4.csv (50 videos)                â”‚
â”‚  ğŸ”¶ Any          â†’ bangla_batch_5.csv (25 videos)                â”‚
â”‚                                                                    â”‚
â”‚  Configuration (already optimal, no changes needed!):             â”‚
â”‚  â€¢ MIN_CHUNK_DURATION = 20                                        â”‚
â”‚  â€¢ MAX_CHUNK_DURATION = 30                                        â”‚
â”‚  â€¢ Word boundaries: Automatic âœ…                                  â”‚
â”‚                                                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€ STEP 3: MERGE RESULTS (2 minutes) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                    â”‚
â”‚  python merge_transcript_batches.py                               â”‚
â”‚                                                                    â”‚
â”‚  Combines everything into bangla_transcripts_merged/             â”‚
â”‚                                                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
PLATFORM SETUP EXAMPLES
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

KAGGLE:
-------
1. Create notebook
2. Add dataset â†’ Upload bangla_batch_0.csv
3. Upload smart_chunk_downloader.py
4. Edit config in smart_chunk_downloader.py:
   
   INPUT_CSV = "/kaggle/input/your-dataset/bangla_batch_0.csv"
   OUTPUT_DIR = "batch_0_transcripts"

5. Run: !python smart_chunk_downloader.py
6. Download batch_0_transcripts/ folder


GOOGLE COLAB:
-------------
1. New notebook
2. Upload files (left sidebar):
   - bangla_batch_1.csv
   - smart_chunk_downloader.py

3. Edit config:
   INPUT_CSV = "bangla_batch_1.csv"
   OUTPUT_DIR = "batch_1_transcripts"

4. Run: !python smart_chunk_downloader.py
5. Zip and download:
   !zip -r batch_1.zip batch_1_transcripts
   Download batch_1.zip


GITHUB CODESPACES:
------------------
1. Create repo, start codespace
2. Upload files
3. Install: pip install youtube-transcript-api pandas
4. Edit config in smart_chunk_downloader.py
5. Run: python smart_chunk_downloader.py
6. Download folder


â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
WHAT EACH CHUNK LOOKS LIKE
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

VIDEO_ID/
â”œâ”€â”€ metadata.json
â”œâ”€â”€ chunk_0000.json  â† 0s to ~26s (random between 20-30)
â”œâ”€â”€ chunk_0000.txt
â”œâ”€â”€ chunk_0001.json  â† ~26s to ~48s (different random)
â”œâ”€â”€ chunk_0001.txt
â”œâ”€â”€ chunk_0002.json  â† ~48s to ~77s (different random)
â””â”€â”€ ...

chunk_0000.json:
{
  "chunk_id": 0,
  "start": 0.0,
  "end": 26.8,
  "duration": 26.8,              â† Random in 20-30s range
  "text": "à¦†à¦¸à¦¸à¦¾à¦²à¦¾à¦®à§ à¦†à¦²à¦¾à¦‡à¦•à§à¦® à¦†à¦œà¦•à§‡ à¦†à¦®à¦°à¦¾...",
  "segments": 6,                 â† Made from 6 subtitle segments
  "target_duration": 24.7        â† Random target picked
}

Key features:
âœ… duration: 26.8s (within 20-30s)
âœ… text: Complete sentences, no cuts
âœ… segments: 6 (ends at natural boundary)


â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
EXPECTED RESULTS FOR 275 VIDEOS
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Videos processed:        ~270-275 (98-100% success rate)
Total chunks:            ~5,000-8,000 chunks
Avg chunks per video:    ~18-30 (depends on video length)
Chunk duration:          20-30 seconds (random, respects words)
Total audio duration:    ~20-25 hours of Bangla content
Storage needed:          ~150-200 MB

Quality metrics:
âœ… No mid-word cuts:     100% (guaranteed by algorithm)
âœ… Natural boundaries:   100% (uses subtitle segments)
âœ… Uniform-ish length:   Yes (20-30s range with variation)


â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
WHY SMART CHUNKING IS PERFECT FOR YOUR USE CASE
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ¯ Speech Recognition Training:
   â†’ Complete words = better phoneme modeling
   â†’ Natural breaks = realistic pause patterns
   â†’ 20-30s = ideal context window for ASR

ğŸ¯ VAD Alignment:
   â†’ Clean boundaries = easier to align
   â†’ No partial words to confuse detection
   â†’ Natural speech patterns preserved

ğŸ¯ Dataset Quality:
   â†’ Professional-grade segmentation
   â†’ Consistent length (but with variety)
   â†’ Ready for any ML framework


â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
MONITORING PROGRESS
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

During download, you'll see:

ğŸ“¥ [142/275] Downloading: nAkV9oOZaz0
   âœ… Success: 13 chunks, avg 24.8s each

The "avg 24.8s" tells you the chunks are working correctly!
Should be between 20-30s on average.

At the end:

â±ï¸  Chunk duration statistics:
   Average: 24.8s         â† Overall average
   Min avg: 22.1s         â† Shortest video average
   Max avg: 27.9s         â† Longest video average
   Target range: 20-30s âœ…

If you see this, everything is perfect! âœ¨


â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
TROUBLESHOOTING
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Problem: "Chunks are 18s or 32s"
â†’ This is fine! At video boundaries or with long segments
â†’ Algorithm prioritizes not cutting words
â†’ 95%+ will be within 20-30s

Problem: "Some chunks are very short"
â†’ Might be last chunk of video
â†’ Or video itself is < 20s
â†’ This is expected and okay!

Problem: Rate limited after 30 videos
â†’ Normal! Progress is saved automatically
â†’ Wait 1-2 hours, re-run (RESUME=True is default)
â†’ Or switch to different platform

Problem: Takes too long
â†’ 50 videos = ~30-45 minutes (normal)
â†’ Running 6 platforms parallel = done in 1 hour!
â†’ Sequential = spread over 2-3 days


â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
USING YOUR CHUNKS
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Load all chunks for training:

```python
import json
from pathlib import Path

chunks = []
for video_dir in Path('bangla_transcripts_merged').iterdir():
    if video_dir.is_dir():
        for chunk_file in sorted(video_dir.glob('chunk_*.json')):
            with open(chunk_file) as f:
                chunk = json.load(f)
                # chunk['text'] = Bangla text
                # chunk['start'] = start time
                # chunk['end'] = end time
                # chunk['duration'] = chunk length
                chunks.append(chunk)

print(f"Loaded {len(chunks)} chunks")
print(f"Avg duration: {sum(c['duration'] for c in chunks) / len(chunks):.1f}s")
```

Get all text for language modeling:

```bash
cat bangla_transcripts_merged/*/chunk_*.txt > all_bangla_text.txt
```

Filter by duration:

```python
# Get only chunks between 22-28 seconds
filtered = [c for c in chunks if 22 <= c['duration'] <= 28]
```


â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
COMPARISON WITH OTHER TOOLS
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

YouTube's Default Download:
âŒ Entire video as 1 file
âŒ Need to manually chunk
âŒ Might cut mid-word when splitting

Fixed-Duration Chunking:
âš ï¸  Exactly 25s chunks
âŒ Cuts mid-word frequently
âŒ Unnatural breaks

Smart Chunking (This Tool):
âœ… 20-30s random chunks
âœ… NEVER cuts mid-word
âœ… Natural speech boundaries
âœ… Perfect for training


â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
READY TO START?
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

You have everything you need:

âœ… videos_with_bangla.csv (275 Bangla videos)
âœ… prepare_bangla_batches.py (splits into 6 batches)
âœ… smart_chunk_downloader.py (downloads with smart chunking)
âœ… merge_transcript_batches.py (combines results)

Next steps:
1. Run: python prepare_bangla_batches.py
2. Upload batches to 6 platforms
3. Run smart_chunk_downloader.py on each
4. Merge everything
5. Start training your models! ğŸš€

See SMART_CHUNKING_EXPLAINED.txt for algorithm details.

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
